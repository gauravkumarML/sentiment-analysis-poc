{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f3fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for categories: ['comp.graphics', 'sci.med']\n",
      "\n",
      "SETUP SUCCESSFUL!\n",
      "Original rows: 1178\n",
      "Cleaned rows:  1138\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\tIt depends on what kind of the polygons. \\...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML&gt; From: libman@hsc.usc.edu (Marlena Libman)\\...</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have posted a DOS MPEG decoder/player to alt...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nGee, what do I do?  My LDL is only 50-60. (a...</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are  complex  bio-medical  images  available  ...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    topic_label\n",
       "0  \\n\\tIt depends on what kind of the polygons. \\...  comp.graphics\n",
       "1  ML> From: libman@hsc.usc.edu (Marlena Libman)\\...        sci.med\n",
       "2  I have posted a DOS MPEG decoder/player to alt...  comp.graphics\n",
       "3  \\nGee, what do I do?  My LDL is only 50-60. (a...        sci.med\n",
       "4  Are  complex  bio-medical  images  available  ...  comp.graphics"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "categories = ['comp.graphics', 'sci.med']\n",
    "\n",
    "print(f\"Loading dataset for categories: {categories}\")\n",
    "data = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=[\"text\"])\n",
    "df['topic_label'] = [data.target_names[t] for t in data.target] \n",
    "\n",
    "\n",
    "original_count = len(df)\n",
    "df = df[df['text'].str.strip().str.len() > 30].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(f\"\\nSETUP SUCCESSFUL!\")\n",
    "print(f\"Original rows: {original_count}\")\n",
    "print(f\"Cleaned rows:  {len(df)}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0389d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "Cleaning Complete!\n",
      "--------------------------------------------------\n",
      "Before cleaning - \n",
      "\tIt depends on what kind of the polygons. \n",
      "\tConvex - simple, concave - trouble, concave with loop(s\n",
      "\n",
      "After cleaning - it depends on what kind of the polygons. convex simple, concave trouble, concave with loop s inside  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text) # remove emails\n",
    "    text = re.sub (r'http\\S+',' ' ,text) # remove hyper links\n",
    "    text = re.sub(r'[^a-zA-Z0-9.,?!]', ' ', text) # remove punctuations\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # remove redundant spaces and formatting mistakes*\n",
    "\n",
    "    return text\n",
    "\n",
    "print(\"Cleaning data...\")\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# compare results\n",
    "\n",
    "print(\"Cleaning Complete!\")\n",
    "print(\"-\"*50)\n",
    "print(f\"Before cleaning - {df['text'][0][:100]}\")\n",
    "print(f\"\\nAfter cleaning - {df['clean_text'][0][:100]} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2fa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation..\n",
      "Fitting the model...\n",
      "Fitting Completed!\n",
      "Found1 topics (Topic -1 = outliers)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>0_image_graphics_jpeg_file</td>\n",
       "      <td>[image, graphics, jpeg, file, data, files, ima...</td>\n",
       "      <td>[i have posted disp135.zip to alt.binaries.pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>562</td>\n",
       "      <td>1_health_don_people_medical</td>\n",
       "      <td>[health, don, people, medical, like, use, just...</td>\n",
       "      <td>[cut here volume 6, number 10 april 20, 1993 !...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                         Name  \\\n",
       "0      0    576   0_image_graphics_jpeg_file   \n",
       "1      1    562  1_health_don_people_medical   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [image, graphics, jpeg, file, data, files, ima...   \n",
       "1  [health, don, people, medical, like, use, just...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [i have posted disp135.zip to alt.binaries.pic...  \n",
       "1  [cut here volume 6, number 10 april 20, 1993 !...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print (\"Initialisation..\")\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "topic_model = BERTopic(embedding_model=\"all-MiniLM-L6-v2\",vectorizer_model=vectorizer_model, min_topic_size=15)\n",
    "\n",
    "print(\"Fitting the model...\")\n",
    "topics, probs = topic_model.fit_transform(df['clean_text'])\n",
    "\n",
    "print(\"Fitting Completed!\")\n",
    "\n",
    "freq = topic_model.get_topic_info()\n",
    "print(f\"Found {len(freq)-1} topic(s) (Topic -1 = outliers)\")\n",
    "display(freq.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "493eaa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic:0_image_graphics_jpeg_file\n",
      "\n",
      "Example Post : i have posted disp135.zip to alt.binaries.pictures.utilities you may distribute this program freely ...\n",
      "Sentiment: NEGATIVE (Confidence: 0.9979368448257446)\n",
      "\n",
      "Topic:1_health_don_people_medical\n",
      "\n",
      "Example Post : cut here volume 6, number 10 april 20, 1993 ! ! ! health info com network ! ! medical newsletter ! e...\n",
      "Sentiment: NEGATIVE (Confidence: 0.9900362491607666)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "top_topics = topic_model.get_topic_info().head(3)\n",
    "\n",
    "for index, row in top_topics.iterrows():\n",
    "    topic_id = row['Topic']\n",
    "\n",
    "    if topic_id == -1:\n",
    "        continue\n",
    "\n",
    "    topic_name = row['Name']\n",
    "\n",
    "    example_post = row['Representative_Docs'][0]\n",
    "\n",
    "    result = sentiment_pipeline(example_post[:512])[0] # 512 BERT limit\n",
    "\n",
    "    print(f\"\\nTopic:{topic_name}\")\n",
    "    print(f\"\\nExample Post : {example_post[:100]}...\")\n",
    "    print(f\"Sentiment: {result['label']} (Confidence: {result['score']})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eeba340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Map saved as 'my_topic_map.html'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fig = topic_model.visualize_barchart(top_n_topics=10)\n",
    "\n",
    "fig.write_html(\"my_topic_map.html\")\n",
    "print(\" Map saved as 'my_topic_map.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ef368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
